{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 216,
      "metadata": {
        "id": "Z6efqHelJ2j6"
      },
      "outputs": [],
      "source": [
        "class MDP:\n",
        "  def __init__(self, init, actlist, terminals, discount = 0.9):\n",
        "    #print(\"initialize the MDP class\")\n",
        "    update(self, init = init, actlist= actlist, terminals = terminals, discount = discount, states = set(), reward ={})\n",
        "  def R(self, state):\n",
        "    #print(\"Return the reward\")\n",
        "    return self.reward[state]\n",
        "\n",
        "  def T(state, action):  #transition state\n",
        "    print(\"Return the probability of the action\")\n",
        "\n",
        "  def actions(self, state): # checking which actions can we take at any particular co-ordinate or node\n",
        "\n",
        "    if state in self.terminals: #means if the agent is in a terminal state then we are not going to take any further action \n",
        "      return None\n",
        "\n",
        "    else:\n",
        "      #\"return the action list\" \n",
        "      \n",
        "      return self.actlist # other than the terminal nodes the agent can take any action from that current state (Left, right, up,down)\n",
        "\n",
        "class GridMDP(MDP):\n",
        "  def __init__(self, grid, terminals, init=(0,0), discount= 0.9):\n",
        "    #print(\"initialize the gridMDP class\")\n",
        "    grid.reverse()\n",
        "    MDP.__init__(self, init, actlist= directions, terminals=terminals, discount=discount)\n",
        "    update(self, grid=grid, rows= len(grid), cols= len(grid[0]))\n",
        "\n",
        "    for x in range(self.cols):\n",
        "      for y in range(self.rows):\n",
        "        self.reward[x,y]=grid[y][x]\n",
        "        if grid[y][x] is not None:\n",
        "          self.states.add((x,y))\n",
        "\n",
        "\n",
        "  def go(self, state, direction):\n",
        "    #print(\"print the next state\")\n",
        "    state1 = vector_add(state, direction)\n",
        "    return if_(state1 in self.states, state1, state) #so that our agents not don't go out of our grid world \n",
        "\n",
        "  def display(self, mapping):\n",
        "    return list(reversed([[mapping.get((x,y), None) for x in range(self.cols)] for y in range(self.rows)]))\n",
        "\n",
        "\n",
        "  def T(self, state, action):\n",
        "    if action==None:\n",
        "      return [(0.0, state)]\n",
        "    else:\n",
        "      return [(0.8, self.go(state, action)), (0.1, self.go(state, turn_left(action))), (0.1, self.go(state, turn_right(action)))] #the probability of taking a particular actionis to move to a next state 0.8"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def update(x, **enteries):\n",
        "  if isinstance(x, dict):\n",
        "    x.update(enteries)\n",
        "  else:\n",
        "    x.__dict__.update(enteries)\n",
        "    return x"
      ],
      "metadata": {
        "id": "fzMgddiDXE-w"
      },
      "execution_count": 217,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def turn_left(direction):\n",
        "  return directions[(directions.index(direction)+1) % len(directions)]\n",
        "\n",
        "def turn_right(direction):\n",
        "  return directions[directions.index(direction)-1]"
      ],
      "metadata": {
        "id": "USs1wkIwho7t"
      },
      "execution_count": 218,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid = [[1,2,3,4], [5,6,7,8],[9,10,11,12]]"
      ],
      "metadata": {
        "id": "KVAQqrR0Xj3V"
      },
      "execution_count": 219,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "grid.reverse()\n",
        "print(*grid, sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZjiTN7mZnGT",
        "outputId": "298d1827-1275-4bb6-81b2-c114c5513c43"
      },
      "execution_count": 220,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[9, 10, 11, 12]\n",
            "[5, 6, 7, 8]\n",
            "[1, 2, 3, 4]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "directions =[(1,0),(0,1),(-1,0),(0,-1)] \n",
        "\n",
        "#left =(-1,0), right =(1,0), Up=(0,1), Down=(0,-1)\n",
        "\n",
        "visual_directions = {(1,0) : \">\", (-1,0) : \"<\", (0,1) : \"^\", (0,-1) : \"v\"} # I just made this visiual dictionary to represent my final extract policy with direction signs"
      ],
      "metadata": {
        "id": "gJXbPfEoczh8"
      },
      "execution_count": 243,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "def vector_add(a,b):\n",
        "  return tuple(map(operator.add, a,b))"
      ],
      "metadata": {
        "id": "c_tqmQZvdT3W"
      },
      "execution_count": 222,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def if_(test, result, alternative):\n",
        "  if test:\n",
        "    return result\n",
        "  else:\n",
        "    return alternative"
      ],
      "metadata": {
        "id": "G4pH1p2PgtYL"
      },
      "execution_count": 223,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "living_reward = 0 # in this case we took living rewars as 0, means the agent is not going to be greedy to reach at the final state or terminal as soon as possible. But if we move the value to the negative side, then our agent will try to reach at the terminal state as soon as possible even if it's negative\n",
        "\n",
        "# here we constracted a world with the living rewards. So you can see the intial grid values of the non-terminal, termial and trap(None) states\n",
        "mdp1 = GridMDP([[living_reward, living_reward, living_reward, +1], [living_reward, None, living_reward, -1], [living_reward,living_reward,living_reward,living_reward]], terminals=[(3,2),(3,1)])"
      ],
      "metadata": {
        "id": "9J8bRfpfjEYn"
      },
      "execution_count": 224,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(mdp1.states)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-6GMKTx9ofwQ",
        "outputId": "fa13de66-e019-4ced-93b9-1b6dc26ad77d"
      },
      "execution_count": 205,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 1), (1, 2), (2, 1), (0, 0), (3, 1), (2, 0), (3, 0), (0, 2), (2, 2), (1, 0), (3, 2)}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "u1 = {s:0 for s in mdp1.states}\n",
        "u = u1.copy()\n",
        "print(u1)\n",
        "print(u.items())\n",
        "\n",
        "for a in mdp1.actions((2,2)):\n",
        "  for(p,s1) in mdp1.T((2,2), a):\n",
        "    print(u1[s1])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WcFYoyaPBMry",
        "outputId": "0a9f3c97-e6c7-45c4-880c-32044f8763c4"
      },
      "execution_count": 206,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{(0, 1): 0, (1, 2): 0, (2, 1): 0, (0, 0): 0, (3, 1): 0, (2, 0): 0, (3, 0): 0, (0, 2): 0, (2, 2): 0, (1, 0): 0, (3, 2): 0}\n",
            "dict_items([((0, 1), 0), ((1, 2), 0), ((2, 1), 0), ((0, 0), 0), ((3, 1), 0), ((2, 0), 0), ((3, 0), 0), ((0, 2), 0), ((2, 2), 0), ((1, 0), 0), ((3, 2), 0)])\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n",
            "0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def value_iterations(mdp = mdp1, iterations = 10):  #here I performed the value iteration task with time-limited point of view but we don't know if the we get the optimal values at the end. So, latter I also performed the optimal value itertion where you don't have to define the iteration time \n",
        "  u_over_time = []\n",
        "  u1 = {s:0 for s in mdp.states}\n",
        "  R,T,discount = mdp.R, mdp.T, mdp.discount\n",
        "\n",
        "  for _ in range(iterations):\n",
        "    u = u1.copy()\n",
        "    for s in mdp.states:\n",
        "      if s in mdp.terminals:\n",
        "        u1[s] = R(s)\n",
        "      else:\n",
        "        print(s)\n",
        "        print(s1)\n",
        "        u1[s] = max([sum([p * (R(s)+ discount*u[s1]) for (p,s1) in T(s,a)]) for a in mdp.actions(s)])\n",
        "    u_over_time.append(u)\n",
        "  return u_over_time"
      ],
      "metadata": {
        "id": "5SUA90UZqqDF"
      },
      "execution_count": 207,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "u_over_time = value_iterations(mdp1)\n",
        "\n",
        "for i in range(10):\n",
        "  print(\"iteraton no \" + str(i))\n",
        "  print(\"\\n\")\n",
        "  print(*mdp1.display(u_over_time[i]), sep=\"\\n\")\n",
        "  print(\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LIf49rGBAsnb",
        "outputId": "6c380086-5c3f-4fe8-87bd-987b4f5cc96e"
      },
      "execution_count": 210,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "(0, 1)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(1, 2)\n",
            "(2, 1)\n",
            "(1, 2)\n",
            "(0, 0)\n",
            "(1, 2)\n",
            "(2, 0)\n",
            "(1, 2)\n",
            "(3, 0)\n",
            "(1, 2)\n",
            "(0, 2)\n",
            "(1, 2)\n",
            "(2, 2)\n",
            "(1, 2)\n",
            "(1, 0)\n",
            "(1, 2)\n",
            "iteraton no 0\n",
            "\n",
            "\n",
            "[0, 0, 0, 0]\n",
            "[0, None, 0, 0]\n",
            "[0, 0, 0, 0]\n",
            "\n",
            "\n",
            "iteraton no 1\n",
            "\n",
            "\n",
            "[0.0, 0.0, 0.0, 1]\n",
            "[0.0, None, 0.0, -1]\n",
            "[0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "\n",
            "iteraton no 2\n",
            "\n",
            "\n",
            "[0.0, 0.0, 0.7200000000000001, 1]\n",
            "[0.0, None, 0.0, -1]\n",
            "[0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "\n",
            "iteraton no 3\n",
            "\n",
            "\n",
            "[0.0, 0.5184000000000001, 0.7848, 1]\n",
            "[0.0, None, 0.42840000000000006, -1]\n",
            "[0.0, 0.0, 0.0, 0.0]\n",
            "\n",
            "\n",
            "iteraton no 4\n",
            "\n",
            "\n",
            "[0.3732480000000001, 0.6583680000000002, 0.8291880000000001, 1]\n",
            "[0.0, None, 0.5136120000000002, -1]\n",
            "[0.0, 0.0, 0.30844800000000006, 0.0]\n",
            "\n",
            "\n",
            "iteraton no 5\n",
            "\n",
            "\n",
            "[0.5076172800000002, 0.7155216000000003, 0.8408520000000002, 1]\n",
            "[0.26873856000000007, None, 0.5532404400000003, -1]\n",
            "[0.0, 0.22208256000000004, 0.3698006400000002, 0.13208256000000002]\n",
            "\n",
            "\n",
            "iteraton no 6\n",
            "\n",
            "\n",
            "[0.5850475776000004, 0.7342073280000003, 0.8454683196000001, 1]\n",
            "[0.41385738240000014, None, 0.5652050796000002, -1]\n",
            "[0.21347919360000006, 0.30623132160000016, 0.43020797760000024, 0.18814389120000014]\n",
            "\n",
            "\n",
            "iteraton no 7\n",
            "\n",
            "\n",
            "[0.6185307225600003, 0.7408945091520002, 0.8469606059280002, 1]\n",
            "[0.4957285847040004, None, 0.5696056472760002, -1]\n",
            "[0.3447512616960001, 0.3648713817600003, 0.45144142646400026, 0.2366826940800002]\n",
            "\n",
            "\n",
            "iteraton no 8\n",
            "\n",
            "\n",
            "[0.6337273842432002, 0.7431726479155202, 0.8474909627883601, 1]\n",
            "[0.5345732654899203, None, 0.5710761445230002, -1]\n",
            "[0.4207906188979203, 0.3907146757708802, 0.46425593286432015, 0.25633926952128017]\n",
            "\n",
            "\n",
            "iteraton no 9\n",
            "\n",
            "\n",
            "[0.6402313649751554, 0.7439645698324131, 0.8476710396580225, 1]\n",
            "[0.5525069044432898, None, 0.5715903462146894, -1]\n",
            "[0.45792822767293473, 0.40459291330106895, 0.4694096791328546, 0.2673348059192257]\n",
            "\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def Optimal_value_iterations(mdp = mdp1, epsilon = 0.001):\n",
        "  \n",
        "  v1 = {s:0 for s in mdp.states}\n",
        "  R,T,discount = mdp.R, mdp.T, mdp.discount\n",
        "  count = 0\n",
        "\n",
        "  while True:\n",
        "    v = v1.copy()\n",
        "    delta = 0\n",
        "    count = count+1\n",
        "\n",
        "    for s in mdp.states:\n",
        "      if s in mdp.terminals:\n",
        "        v1[s] = R(s)\n",
        "      else:\n",
        "        v1[s] = max([sum([p * (R(s)+ discount*v[s1]) for (p,s1) in T(s,a)]) for a in mdp.actions(s)])\n",
        "\n",
        "      delta = max(delta, abs(v1[s]-v[s]))\n",
        "\n",
        "    if delta < epsilon:\n",
        "\n",
        "      print(\"values optimized at iteration no: \" + str(count))\n",
        "      return v\n",
        "    \n"
      ],
      "metadata": {
        "id": "EM7FBlDjqPMt"
      },
      "execution_count": 231,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimized_u = Optimal_value_iterations(mdp1)\n",
        "\n",
        "print(\"Optimal state values\")\n",
        "print(*mdp1.display(optimized_u), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Xuz0dGg8v1kl",
        "outputId": "405061d8-c852-41bf-a9ba-aa3546d0c3f8"
      },
      "execution_count": 247,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "values optimized at iteration no: 16\n",
            "Optimal state values\n",
            "[0.6449472665878168, 0.7443794501753827, 0.8477661188408148, 1]\n",
            "[0.5662439726531641, None, 0.5718585829794186, -1]\n",
            "[0.4902998037829586, 0.42987207149041445, 0.4752173643973898, 0.27686990880812257]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def argmax(seq, fn): \n",
        "\n",
        "  best = seq[0]\n",
        "  best_score = fn(best)\n",
        "  for x in seq:\n",
        "    x_score = fn(x)\n",
        "    if x_score > best_score:\n",
        "      best =x\n",
        "      best_score = x_score\n",
        "  return best"
      ],
      "metadata": {
        "id": "osaqKM_Yxy_L"
      },
      "execution_count": 239,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def min_expmax(s,a, mdp, u):\n",
        "  R,T, discount= mdp.R, mdp.T, mdp.discount\n",
        "  li = []\n",
        "\n",
        "  for(p,s1) in T(s,a):\n",
        "    temp = p*(R(s)+  discount*u[s1])\n",
        "    li.append(temp)\n",
        "    return sum(li)"
      ],
      "metadata": {
        "id": "ibY4RzgIy33_"
      },
      "execution_count": 240,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def policy_extraction(mdp, u):\n",
        "  R,T, discount= mdp.R, mdp.T, mdp.discount\n",
        "\n",
        "  pi = {s:'x' for s in mdp.states}\n",
        "\n",
        "  for s in mdp.states:\n",
        "    if s in mdp.terminals:\n",
        "      pi[s] = 'x'\n",
        "    else:\n",
        "      temp = argmax(mdp.actions(s), lambda a: min_expmax(s,a,mdp,u))\n",
        "      pi[s] = visual_directions[temp]\n",
        "  return pi\n"
      ],
      "metadata": {
        "id": "i7M4WjxA0JvI"
      },
      "execution_count": 245,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "policy = policy_extraction(mdp1, optimized_u)\n",
        "\n",
        "\n",
        "print(\"Extracted-optimal policy: \\n\")\n",
        "print(*mdp1.display(policy), sep=\"\\n\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c7cZEdQL14rh",
        "outputId": "2030ce5d-e0a5-4071-cf13-02d8baf52861"
      },
      "execution_count": 249,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracted-optimal policy: \n",
            "\n",
            "['>', '>', '>', 'x']\n",
            "['^', None, '^', 'x']\n",
            "['^', '<', '^', '<']\n"
          ]
        }
      ]
    }
  ]
}